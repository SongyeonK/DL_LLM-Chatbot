import axios from 'axios';
// import { HumanMessage } from "@langchain/core/messages";
import OpenAI from "openai";
// import { ChatOpenAI } from '@langchain/openai';
import { HfInference } from '@huggingface/inference';

// API í´ë¼ì´ì–¸íŠ¸ë¥¼ ìƒì„±í•˜ëŠ” íŒ©í† ë¦¬ í•¨ìˆ˜
export const createApiClient = async (modelId) => {
  if (!modelId) {
    throw new Error("Model ID is not defined");
  }
  const models = await fetchModelsFromDatabase();  
  const model = models.find(m => m.MODEL_ID === modelId);

  if (!model || !model.MODEL_NAME) {
    throw new Error(`Model with ID ${modelId} not found or MODEL_NAME is undefined`);
  }

  const configuration = {
    openaiApiKey: process.env.VUE_APP_OPENAI_API_KEY,
    huggingfaceApiKey: process.env.VUE_APP_HUGGINGFACE_API_KEY,
    anthropicApiKey: process.env.VUE_APP_ANTHROPIC_API_KEY,
    cohereApiKey: process.env.VUE_APP_COHERE_API_KEY,
    modelName: model.MODEL_NAME,
  };

  switch (model.MODEL_NAME.toLowerCase()) {
    case 'gpt-4o-mini':
    case 'gpt-4o':
    case 'gpt-3.5-turbo': {
      const openaiClient = new OpenAI({
        apiKey: configuration.openaiApiKey,
        dangerouslyAllowBrowser: true,  // ë¸Œë¼ìš°ì € í™˜ê²½ì—ì„œ ì‚¬ìš©ì„ í—ˆìš©
      });
      // const openaiClient = new ChatOpenAI({
      //   apiKey: configuration.openaiApiKey,
      //   model: configuration.modelName
      // });
      return { client: openaiClient, modelName: configuration.modelName };
    }
    case 'meta-llama/meta-llama-3-70b-instruct': 
    case 'meta-llama/meta-llama-3-8b-instruct': 
    case 'mistralai/mistral-7b-instruct-v0.3': 
    case 'mistralai/mistral-7b-instruct-v0.2': 
    case 'upstage/solar-10.7b-instruct-v1.0': 
    {
      const hfClient = new HfInference(configuration.huggingfaceApiKey);
      return { client: hfClient, modelName: configuration.modelName };
    }
    default:
      throw new Error('Unsupported API provider');
  }
};

// LLMë³„ë¡œ chatí•˜ëŠ” ë©”ì†Œë“œ
export const createChatCompletion = async (client, modelName, messages, options = {}) => {
  // options ê¸°ë³¸ê°’ ì„¤ì •
  const { temperature = 0.7, top_p = 0.9 } = options;

  if (client instanceof OpenAI) {
    let response = '';
    const completion = await client.chat.completions.create({
      model: modelName,
      messages: messages,
      temperature: temperature,
      top_p: top_p,
      stream: true,
    });
    for await (const chunk of completion) {
      response += chunk.choices[0]?.delta?.content || "";
    }
    return response;
  } else if (client instanceof HfInference) {
    let response = '';
    console.log('messages : ', messages);
    for await (const chunk of client.chatCompletionStream({
      model: modelName,
      messages: messages,
      temperature: temperature,
      max_tokens: options.max_tokens || 500,
    })) {
      response += chunk.choices[0]?.delta?.content || "";
    }
    return response;
  }  
};

// ëª¨ë¸ ëª©ë¡ì„ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜
export const fetchModelsFromDatabase = async () => {
  try {
    const response = await axios.get('/api/config/getLLMConfig');
    return response.data.models;
  } catch (error) {
    console.error('Error fetching models from database:', error);
    throw error;
  }
};

// íŠ¹ì • ëª¨ë¸ì˜ ì˜µì…˜ì„ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜
export const fetchOptionsFromDatabase = async (modelId) => {
  try {
    const response = await axios.get('/api/config/getLLMConfig');
    return response.data.options.filter(option => option.MODEL_ID === modelId);
  } catch (error) {
    console.error('Error fetching options from database:', error);
    throw error;
  }
};

// LLM êµ¬ì„± ë°ì´í„°(ëª¨ë¸ëª©ë¡ê³¼ ì˜µì…˜ ëª¨ë‘)ë¥¼ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜
export const getLLMConfig = async () => {
  try {
    // LLM config ë°ì´í„°ë¥¼ ì„œë²„ì—ì„œ ê°€ì ¸ì˜´
    const response = await axios.get('/api/config/getLLMConfig');
    // localStorageì—ì„œ embeddingModel ê°’ì„ ì½ì–´ì˜´
    let embeddingModel = localStorage.getItem('embeddingModel');
    // ë§Œì•½ localStorageì— ê°’ì´ ì—†ë‹¤ë©´ ê¸°ë³¸ê°’ì„ ì„¤ì •
    if (!embeddingModel) {
      embeddingModel = 'doc_model_han';
      localStorage.setItem('embeddingModel', embeddingModel);  // ê¸°ë³¸ê°’ì„ localStorageì— ì €ì¥
    }
    // embedding_modelì„ response.dataì— ì¶”ê°€
    response.data.embedding_model = embeddingModel;
    return response.data;
  } catch (error) {
    console.error('Error loading LLM config:', error);
    throw error;
  }
};

export const loadLLMConfig = async () => {
  try {
    const data = await getLLMConfig();
    const embedding_model = data.embedding_model;
    const models = data.models.filter(model => 
      model.MODEL_NAME === 'gpt-4o-mini' || model.MODEL_NAME === 'gpt-4o' || model.MODEL_NAME === 'gpt-3.5-turbo'
    );
    const defaultModel = data.models.find(model => model.DEFAULT_MODEL_YN === 'Y');
    
    if (defaultModel) {
      return {
        selectedModelId: defaultModel.MODEL_ID,
        selectedModelName: defaultModel.MODEL_NAME,
        embedding_model,
        models
      };
    } else {
      console.error('No default model found');
      return null;
    }
  } catch (error) {
    console.error('Error loading LLM config:', error);
    throw error;
  }
};

export const setDefaultModel = async (modelId) =>  {
  try {
    const response = await axios.post('/api/config/updateLLMModel', { model_id: modelId });
    if (response.status === 200) {
      // console.log('Default model updated successfully : ', modelId);
    }
  } catch (error) {
    console.error('Error setting default model:', error);
  }
};

// ì±„íŒ… ë°©ì„ ì €ì¥í•˜ëŠ” í•¨ìˆ˜
export const saveChatRoom = async () => {
  try {
    const historyResponse = await axios.post('/api/chatbot/saveHistory', { chat_room_id: 'room' + Date.now(), title: '' });
    return {
      chatId: historyResponse.data.chat_id,
      chatRoomId: historyResponse.data.chat_room_id
    };
  } catch (error) {
    console.error('Error saving chat room:', error);
    throw new Error('ì±„íŒ… ë°© ì €ì¥ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.');
  }
};

// ì±„íŒ… ë©”ì‹œì§€ë¥¼ ì €ì¥í•˜ëŠ” í•¨ìˆ˜
export const saveChatMessage = async (chatId, userId, content, role) => {
  try {
    await axios.post('/api/chatbot/saveChat', { chat_id: chatId, user_id: userId, content, role });
  } catch (error) {
    console.error('Error saving message:', error);
    throw new Error(`${role === 'user' ? 'ì‚¬ìš©ì' : 'ë´‡'} ë©”ì‹œì§€ ì €ì¥ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.`);
  }
};

// Gabage Chat ì‚­ì œ í™•ì¸ ë° ì‹¤í–‰
export const deleteNullChat = async () => {
  try {
    const response = await axios.delete('/api/chatbot/deleteNullChat');
    if (response.status === 200) {
      // console.log('Unfinished Null chat room and messages deleted');
    }
  } catch (error) {
    console.error('Error deleting Null chat room and messages:', error);
  }
};

// ì…ë ¥ filenameì˜ ë°”ì´íŠ¸ í¬ê¸° ê³„ì‚°
export const calculateByteLength = async (fileName) => {
  // NFD í¬ë§· ì—¬ë¶€ í™•ì¸
  const isNFD = fileName !== fileName.normalize('NFC');
  let byteLength = 0;

  for (let char of fileName) {
    const codePoint = char.codePointAt(0);
    // í•œê¸€ ì—¬ë¶€ í™•ì¸ (ìœ ë‹ˆì½”ë“œ ë²”ìœ„: U+AC00 ~ U+D7A3)
    if (codePoint >= 0xAC00 && codePoint <= 0xD7A3) {
      // NFD í¬ë§·ì¸ ê²½ìš°
      if (isNFD) {
        // ë°›ì¹¨ ë¬¸ìê°€ ìˆëŠ”ì§€ í™•ì¸ (ììŒ, ëª¨ìŒìœ¼ë¡œë§Œ êµ¬ì„±ëœ ê²½ìš°ëŠ” 2ë°”ì´íŠ¸, ë°›ì¹¨ ìˆëŠ” ê²½ìš°ëŠ” 3ë°”ì´íŠ¸)
        const jamo = char.normalize('NFD');
        byteLength += jamo.length === 3 ? 3 : 2;
      } else {
        // NFC í¬ë§·ì¸ ê²½ìš° í•œê¸€ì€ 3ë°”ì´íŠ¸
        byteLength += 3;
      }
    } else {
      // í•œê¸€ì´ ì•„ë‹Œ ë¬¸ìì˜ ê²½ìš° ê¸°ë³¸ ë°”ì´íŠ¸ ê¸¸ì´ ê³„ì‚°
      byteLength += new TextEncoder().encode(char).length;
    }
  }
  return byteLength;
};

export const formatMessage = (text, isUser) => {
  const escapeHtml = (text) => {
    return text
      .replace(/&/g, '&amp;')
      .replace(/</g, '&lt;')
      .replace(/>/g, '&gt;')
      .replace(/"/g, '&quot;')
      .replace(/'/g, '&#039;');
  };

  const escapedText = escapeHtml(text);
  // SQL ë“¤ì—¬ì“°ê¸°ë¥¼ ìœ„í•œ ë¡œì§ ì¶”ê°€
  const indent = ' '.repeat(10);  // "SQL" : " ì˜ ê¸¸ì´ì— í•´ë‹¹í•˜ëŠ” ê³µë°± ìƒì„±

  let formattedText = escapedText
    .replace(/\\n/g, `<br>${indent}`)  // '\n' ë¬¸ìì—´ì„ <br>ë¡œ ë³€í™˜
    .replace(/\n/g, '<br>')  // ì¤„ë°”ê¿ˆ ë¬¸ìë¥¼ <br>ë¡œ ë³€í™˜
    .replace(/(^|<br>)(\s+)/g, (match, p1, p2) => p1 + p2.replace(/ /g, '&nbsp;'));
  
  // íŠ¹ì • í‚¤ì›Œë“œì— ìƒ‰ìƒ ì ìš©
  formattedText = formattedText
    .replace(/GEN_SQL/g, '<span style="color: var(--text-highlight2-color); font-weight: bold;">GEN_SQL</span>')

    .replace(/ìš”ì•½/g, '<span style="color: var(--text-highlight3-color); font-weight: bold;">ìš”ì•½</span>')
    .replace(/ì‹œì‚¬ì /g, '<span style="color: var(--text-highlight3-color); font-weight: bold;">ì‹œì‚¬ì </span>')
    .replace(/QueryResult/g, '<span style="color: var(--text-highlight3-color); font-weight: bold;">QueryResult</span>')

    .replace(/SQLìì—°ì–´/g, '<span style="color: var(--text-highlight3-color); font-weight: bold;">SQLìì—°ì–´</span>')
    .replace(/Input SQL/g, '<span style="font-weight: bold;">Input SQL</span>')
    .replace(/Reviewed SQL/g, '<span style="color: var(--text-highlight2-color); font-weight: bold;">Reviewed SQL</span>')
    .replace(/ìˆ˜ì • ê·¼ê±°/g, '<span style="color: var(--text-highlight3-color); font-weight: bold;">ìˆ˜ì • ê·¼ê±°</span>')

    .replace(/ìµœì¢… SQL/g, '<span style="color: var(--text-highlight3-color); font-weight: bold;">ìµœì¢… SQL</span>')

    .replace(/ìˆ˜ì • ì œì•ˆ/g, '<span style="color: var(--text-highlight2-color); font-weight: bold;">ìˆ˜ì • ì œì•ˆ</span>')
    .replace(/ìˆ˜ì • í›„/g, '<span style="color: var(--text-highlight3-color); font-weight: bold;">ìˆ˜ì • í›„</span>')

    .replace(/ë²ˆì—­ë¬¸/g, '<span style="font-weight: bold;">ë²ˆì—­ë¬¸</span>')
    .replace(/ITìš©ì–´ ì‚¬ì „ í™œìš©/g, '<span style="color: var(--text-highlight3-color); font-weight: bold;">ITìš©ì–´ ì‚¬ì „ í™œìš©</span>');


  if (isUser) {
    return `<span style="font-size: 1.2em;">ğŸ•µğŸ½</span> ${formattedText}`;
  } else {
    return `<span style="font-size: 1.2em;">ğŸ¤–</span> ${formattedText}`;
  }
};

// ğŸ™†ğŸ½â€â™‚ï¸ ğŸ§‘ğŸ½â€ğŸš€ ğŸ§‘ğŸ½â€ğŸ’» ğŸ•µğŸ½

// formatJSON í˜„ì¬ ì‚¬ìš©í•˜ì§€ ì•Šìœ¼ë‚˜, ë‚˜ì¤‘ì—....
export const formatJSON = (text) => {
  const jsonString = text;
  try {
    // ì´ë¯¸ ê°ì²´ì¸ ê²½ìš° ì²˜ë¦¬í•˜ì§€ ì•Šê³  ë°”ë¡œ ë°˜í™˜
    if (typeof jsonString === 'object') {
      return JSON.stringify(jsonString, null, 2).replace(/\n/g, '<br>').replace(/\s/g, '&nbsp;');
    }
    const jsonObject = JSON.parse(jsonString);
    return JSON.stringify(jsonObject, null, 2).replace(/\n/g, '<br>').replace(/\s/g, '&nbsp;');
  } catch (error) {
    console.error('Invalid JSON string:', error);
    return jsonString; // JSON í¬ë§·ì´ ì˜ëª»ëœ ê²½ìš° ì›ë³¸ ë¬¸ìì—´ ë°˜í™˜
  }
};

export const formatTimestamp = (timestamp) => {
  // íŒŒë¼ë¯¸í„°ê°€ ì—†ìœ¼ë©´ í˜„ì¬ ì‹œê°„ì„ ì‚¬ìš©
  const date = timestamp ? new Date(timestamp) : new Date();

  const year = date.getFullYear();
  const month = String(date.getMonth() + 1).padStart(2, '0');
  const day = String(date.getDate()).padStart(2, '0');
  const hours = String(date.getHours()).padStart(2, '0');
  const minutes = String(date.getMinutes()).padStart(2, '0');
  const seconds = String(date.getSeconds()).padStart(2, '0');
  
  return `${year}-${month}-${day} ${hours}:${minutes}:${seconds}`;
};

export const scrollToBottom = (ref) => {
  if (ref) {
    setTimeout(() => {
      ref.scrollTop = ref.scrollHeight;
    }, 100); // 100ms ì§€ì—° ì‹œê°„ì„ ì¶”ê°€í•˜ì—¬ DOMì´ ì¤€ë¹„ë˜ì—ˆëŠ”ì§€ í™•ì¸
  } else {
    console.error('Reference is undefined');
  }
};